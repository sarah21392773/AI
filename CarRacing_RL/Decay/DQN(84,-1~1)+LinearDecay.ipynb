{"cells":[{"cell_type":"markdown","metadata":{"id":"amCJWZusYFA7"},"source":["# import 必要套件"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"q4DQXqSMYKJF","executionInfo":{"status":"ok","timestamp":1758948820029,"user_tz":-480,"elapsed":8,"user":{"displayName":"科展","userId":"12569582977464496580"}}},"outputs":[],"source":["import random\n","import time,math\n","import numpy as np\n","import gymnasium as gym\n","import gymnasium.wrappers as gym_wrap\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation #輸出動畫影片\n","from IPython import display\n","from tqdm import tqdm"]},{"cell_type":"code","source":["!pip install gymnasium"],"metadata":{"id":"9dvueEORhUt2","executionInfo":{"status":"ok","timestamp":1758948858475,"user_tz":-480,"elapsed":7023,"user":{"displayName":"科展","userId":"12569582977464496580"}},"outputId":"010c589f-8819-44a8-8cd2-968ea488afe2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.0)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Rp64v20dxLw"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import collections\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m9OEfP8WxULF"},"outputs":[],"source":["class ImageEnv(gym.Wrapper):\n","  def __init__(self,env,stack_frames=4,delay_op=50):\n","    super(ImageEnv, self).__init__(env)\n","    self.delay_op = delay_op\n","    self.stack_frames = stack_frames\n","  def reset(self):\n","    s, info = self.env.reset()\n","    for i in range(self.delay_op):\n","      s, r, terminated, truncated, info = self.env.step(0)\n","      s=s[:84, 6:90]/255.0\n","      self.stacked_state = np.tile( s , (self.stack_frames,1,1) )  # [4, 84, 84]\n","    return self.stacked_state, info\n","\n","  def step(self, action):\n","    reward = 0\n","    for _ in range(self.stack_frames):\n","      s, r, terminated, truncated, info = self.env.step(action)\n","      if r==-100:terminated=True\n","      s=s[:84, 6:90]/255.0\n","      reward += r\n","      if terminated or truncated:break\n","      self.stacked_state = np.concatenate((self.stacked_state[1:], s[np.newaxis]), axis=0)\n","    return self.stacked_state, reward, terminated, truncated, info"]},{"cell_type":"markdown","metadata":{"id":"Av7Taco9YPQQ"},"source":["# 建立Replay Buffer類別"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysgw8Va1I3TF"},"outputs":[],"source":["class ReplayBuffer:\n","  def __init__(self,max_size=int(1e5), num_steps=1):\n","    self.s = np.zeros((max_size,4,84,84), dtype=np.float32)\n","    self.a = np.zeros((max_size,), dtype=np.int64)\n","    self.r = np.zeros((max_size, 1), dtype=np.float32)\n","    self.s_ = np.zeros((max_size,4,84,84), dtype=np.float32)\n","    self.done = np.zeros((max_size, 1), dtype=np.float32)\n","    self.ptr = 0\n","    self.size = 0\n","    self.max_size = max_size\n","    self.num_steps = num_steps\n","\n","  def append(self,s,a,r,s_,done):\n","    self.s[self.ptr] = s\n","    self.a[self.ptr] = a\n","    self.r[self.ptr] = r\n","    self.s_[self.ptr] = s_\n","    self.done[self.ptr] = done\n","    self.ptr = (self.ptr + 1) % self.max_size\n","    self.size = min(self.size+1,self.max_size)\n","  def sample(self, batch_size):\n","    ind = np.random.randint(0, self.size, batch_size)\n","    return torch.FloatTensor(self.s[ind]),torch.LongTensor(self.a[ind]),torch.FloatTensor(self.r[ind]),torch.FloatTensor(self.s_[ind]),torch.FloatTensor(self.done[ind])"]},{"cell_type":"markdown","metadata":{"id":"VySf61of0cRe"},"source":["# 搭建DQN神經網路的類別"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"045GAtxseMMq"},"outputs":[],"source":["class DQN(torch.nn.Module):\n","  def __init__(self,n_act):\n","    super(DQN,self).__init__()\n","    self.conv1 = torch.nn.Conv2d(4, 16, kernel_size=8, stride=4)  #[N,4,84,84]->[N,16,20,20]\n","    self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=4, stride=2)  #[N,16,20,20]->[N,32,9,9]\n","    self.fc1 = torch.nn.Linear(32 * 9 * 9, 256)\n","    self.fc2 = torch.nn.Linear(256, n_act)\n","  def forward(self,x):\n","    x = F.relu(self.conv1(x))\n","    x = F.relu(self.conv2(x))\n","    x = x.view((-1, 32 * 9 * 9))\n","    x = self.fc1(x)\n","    x = self.fc2(x)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"VWP0oC3fZ3gl"},"source":["# 設定是否載入模型參數，舊參數檔路徑，新參數檔路徑"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WS0qfHErbbMc"},"outputs":[],"source":["Load_File=0\n","Old_File=f\"Model-{Load_File}.pt\"\n","if Load_File>0:\n","  Log= np.load(f\"Log-{Load_File}.npy\", allow_pickle=True).item()\n","else:\n","  Log={\"TrainReward\":[],\"TestReward\":[],\"Loss\":[]}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uhbUUe6j25S5","scrolled":true},"outputs":[],"source":["env=gym.make('CarRacing-v3',render_mode=\"rgb_array\",domain_randomize=False, continuous=False)\n","env = gym_wrap.GrayscaleObservation(env)\n","env = ImageEnv(env)"]},{"cell_type":"markdown","metadata":{"id":"T2ZraJED0kT-"},"source":["# 搭建智能體Agent的類別"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AhLrFKG5bExq"},"outputs":[],"source":["class DQNAgent():\n","  def __init__(self,gamma=0.9,eps_low=0.1,lr=0.00025):\n","    self.env = env\n","    self.n_act=self.env.action_space.n\n","    self.PredictDQN= DQN(self.n_act)\n","    self.TargetDQN= DQN(self.n_act)\n","    if Load_File>0:\n","      self.PredictDQN.load_state_dict(torch.load(Old_File))\n","      self.TargetDQN.load_state_dict(torch.load(Old_File))\n","    self.PredictDQN.to(device)\n","    self.TargetDQN.to(device)\n","    self.LossFun=torch.nn.SmoothL1Loss()\n","    self.optimizer=torch.optim.Adam(self.PredictDQN.parameters(),lr=lr)\n","    self.gamma=gamma\n","    self.eps_low=eps_low\n","    self.rb=ReplayBuffer(max_size=10000, num_steps=1)\n","  def PredictA(self,s):\n","    with torch.no_grad():\n","      return torch.argmax(self.PredictDQN(torch.FloatTensor(s).to(device))).item()\n","  def SelectA(self,a):\n","    return self.env.action_space.sample() if np.random.random()<self.EPS else a\n","  def Train(self,N_EPISODES):\n","    for i in tqdm(range(Load_File,N_EPISODES)):\n","      self.EPS=max( 1-i*(1-self.eps_low)/(5*N_EPISODES/10) , self.eps_low)\n","      total_reward=0\n","      s,_=self.env.reset()\n","      while True:\n","        a=self.SelectA(self.PredictA(s))\n","        s_,r,done,stop,_=self.env.step(a)\n","        self.rb.append(s,a,r,s_,done)\n","        if self.rb.size > 200 and i%self.rb.num_steps==0:self.Learn()\n","        if i % 20==0:  self.TargetDQN.load_state_dict(self.PredictDQN.state_dict())\n","        s=s_\n","        total_reward+=r\n","        if done or stop:break\n","      print(f\"\\n{total_reward}\")\n","      Log[\"TrainReward\"].append(total_reward)\n","      if i % 10 == 9:\n","        test_reward=self.Test()\n","        print(f\"\\n訓練次數{i+1}，總回報{test_reward}\")\n","        Log[\"TestReward\"].append(test_reward)\n","        torch.save(self.PredictDQN.state_dict(), f\"Model-{i+1}.pt\")\n","        np.save(f\"Log-{i+1}.npy\", Log)\n","  def Learn(self):\n","    self.optimizer.zero_grad()\n","    batch_s, batch_a, batch_r, batch_s_, batch_done=self.rb.sample(32)\n","    predict_Q = (self.PredictDQN(batch_s.to(device))*F.one_hot(batch_a.long().to(device),self.n_act)).sum(1,keepdims=True)\n","    with torch.no_grad():\n","      target_Q = batch_r.to(device)+(1-batch_done.to(device))*self.gamma*self.TargetDQN(batch_s_.to(device)).max(1,keepdims=True)[0]\n","    loss = self.LossFun(predict_Q, target_Q)\n","    Log[\"Loss\"].append(float(loss))\n","    loss.backward()\n","    self.optimizer.step()\n","  def Test(self,VIDEO=False):\n","    total_reward=0\n","    video=[]\n","    s,_=self.env.reset()\n","    while True:\n","      video.append(self.env.render())\n","      a=self.PredictA(s)\n","      s,r,done,stop,_=self.env.step(a)\n","      total_reward+=r\n","      if done or stop:break\n","    if VIDEO:\n","      patch = plt.imshow(video[0]) #產生展示圖形物件\n","      plt.axis('off') #關閉坐標軸\n","      def animate(i): #設定更換影格的函數\n","        patch.set_data(video[i])\n","        #plt.gcf()=>建新繪圖區 animate=>更換影格函數 frames=>影格數 interval=>影隔間距(毫秒)\n","      anim = animation.FuncAnimation(plt.gcf(),animate,frames=len(video),interval=200)\n","      anim.save('Car_racing.mp4') #儲存為mp4擋\n","    return total_reward\n","  def Record(self):\n","    total_reward=0\n","    s,_=self.env.reset()\n","    while True:\n","      image=self.env.render()\n","      plt.imshow(image)\n","      #plt.imsave(f\"/content/drive/MyDrive/recording/{str(int(time.time()))}.png\", image)\n","      a=self.PredictA(s)\n","      s,r,done,stop,_=self.env.step(a)\n","      print(r)\n","      total_reward+=r\n","      plt.pause(0.1)\n","      #清除目前的顯示\n","      display.clear_output(wait=True)\n","      if done or stop:break\n","    print(total_reward)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NyD5MRkycJKL"},"outputs":[],"source":["Agent=DQNAgent(gamma=0.95,eps_low=0.05,lr=0.00025)\n","Agent.Train(N_EPISODES=5000)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":414},"executionInfo":{"elapsed":127019,"status":"ok","timestamp":1736345812745,"user":{"displayName":"邱崑山","userId":"14834293939722930553"},"user_tz":-480},"id":"QJvLkbBOtFjm","outputId":"481aaed5-e92e-4bf7-ebb6-868ff945f46e"},"outputs":[{"name":"stdout","output_type":"stream","text":["629.4094488188853\n"]}],"source":["Agent.Record()"]},{"cell_type":"code","source":["      #線性衰減策略\n","self.EPS=max( 1-i*(1-self.eps_low)/(x*N_EPISODES/10) , self.eps_low) # x=1、3、5、7、9、10"],"metadata":{"id":"Z0A41Xe57Ocg"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1r5QT83LxUHE47Lex9v9P55s7eb_W0mHC","timestamp":1736245847989},{"file_id":"1O1KfjoTBUrBCnyn4oXtG4lcTEvRSZK7G","timestamp":1735479867704},{"file_id":"18yt9b6qYCT2PsLDYbl9fv6zRcSQvmi0n","timestamp":1709199071555},{"file_id":"1WRLanvHf4yYOnDBxmb0n1mbrLON0KMQU","timestamp":1708675711282},{"file_id":"13Cp-YFwmlHN3MbI7_xlKuLd_y_TaPV-0","timestamp":1702823835064},{"file_id":"1aMcCpvOHmXrOq1JcpI7evtg_4ZvR4qVH","timestamp":1702822403410},{"file_id":"1xHVDpXOYdYhmF3tU9vPo2TaMb81FA3Gl","timestamp":1702274368848},{"file_id":"1MKlvW9tFlfUpTKXu42vIdU66ffXCLYFx","timestamp":1701668882207},{"file_id":"1sbhFnBreRKtQfdR7Ta5P5ndy1xqZV7z3","timestamp":1699250308091},{"file_id":"1q95n7kJ49u2_x8SyBPyfHTB-_HfZ_wFt","timestamp":1693963108981},{"file_id":"1K98cGRSf_HKeLpHpuChr8vtaaMjPE-7x","timestamp":1693961359885},{"file_id":"1S2n19RA0RAkTfq_uA7vGSUBHDZMHTRAK","timestamp":1693878549390},{"file_id":"1DLZ6g1KLbo6VVZXw4zJ3xSxYO-U18ngr","timestamp":1693813383392},{"file_id":"1ipxvXg17g79lUSrBgMEivSDBot1LaN8H","timestamp":1693566531232},{"file_id":"1FfCLgXyAyL3yb2o92dcm3qv3uF_A22k5","timestamp":1693531204519}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}