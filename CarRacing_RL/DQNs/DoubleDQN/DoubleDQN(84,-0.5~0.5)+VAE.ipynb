{"cells":[{"cell_type":"markdown","metadata":{"id":"amCJWZusYFA7"},"source":["# Import Site-Package"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4DQXqSMYKJF"},"outputs":[],"source":["import random\n","import time,math\n","import numpy as np\n","import gymnasium as gym\n","import gymnasium.wrappers as gym_wrap\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation #輸出動畫影片\n","from IPython import display\n","from tqdm import tqdm\n","import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import collections"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dvj6InvIYhLR","outputId":"4b1efd10-b893-44f4-b9f7-ceca7d364c1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n"]}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"Av7Taco9YPQQ"},"source":["# Replay Buffer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysgw8Va1I3TF"},"outputs":[],"source":["class ReplayBuffer:\n","  def __init__(self,max_size=int(1e5), num_steps=1):\n","    self.s = np.zeros((max_size,4,64), dtype=np.float32)\n","    self.a = np.zeros((max_size,), dtype=np.int64)\n","    self.r = np.zeros((max_size, 1), dtype=np.float32)\n","    self.s_ = np.zeros((max_size,4,64), dtype=np.float32)\n","    self.done = np.zeros((max_size, 1), dtype=np.float32)\n","    self.ptr = 0\n","    self.size = 0\n","    self.max_size = max_size\n","    self.num_steps = num_steps\n","\n","  def append(self,s,a,r,s_,done):\n","    self.s[self.ptr] = s\n","    self.a[self.ptr] = a\n","    self.r[self.ptr] = r\n","    self.s_[self.ptr] = s_\n","    self.done[self.ptr] = done\n","    self.ptr = (self.ptr + 1) % self.max_size\n","    self.size = min(self.size+1,self.max_size)\n","  def sample(self, batch_size):\n","    ind = np.random.randint(0, self.size, batch_size)\n","    return torch.FloatTensor(self.s[ind]),torch.LongTensor(self.a[ind]),torch.FloatTensor(self.r[ind]),torch.FloatTensor(self.s_[ind]),torch.FloatTensor(self.done[ind])"]},{"cell_type":"markdown","metadata":{"id":"kjtqIe8PDtfD"},"source":["# VAE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tlRMMlk5DtfG","outputId":"8c9867f3-fc79-416a-9a20-a4198ad25632"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["input_size = 84 * 84\n","hidden_size = 800\n","latent_size = 64\n","class VAEEncoder(nn.Module):\n","    def __init__(self, input_size, hidden_size, latent_size):\n","        super().__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, latent_size*2)\n","\n","    def forward(self, x):\n","        x = self.fc2( torch.relu(self.fc1(x)) )\n","        mean, log_var = x.split(latent_size, dim=1)\n","        return mean, log_var\n","class VAEDecoder(nn.Module):\n","    def __init__(self, latent_size, hidden_size, output_size):\n","        super().__init__()\n","        self.fc1 = nn.Linear(latent_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        x = torch.sigmoid( self.fc2( torch.relu(self.fc1(x)) ) )-0.5\n","        return x\n","class VAE(nn.Module):\n","    def __init__(self, input_size, hidden_size, latent_size):\n","        super().__init__()\n","        self.encoder = VAEEncoder(input_size, hidden_size, latent_size)\n","        self.decoder = VAEDecoder(latent_size, hidden_size, input_size)\n","\n","    def forward(self, x):\n","        mean, log_var = self.encoder(x)\n","        std = torch.exp(0.5 * log_var)\n","        eps = torch.randn_like(std).to(device)\n","        z = mean + std * eps    #random sampling\n","        reconstruct = self.decoder(z)\n","        return reconstruct, mean, log_var\n","model = VAE(input_size, hidden_size, latent_size)\n","model.load_state_dict(torch.load(f'VAE_16000.pth',weights_only=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3MEKyxzkIPIV"},"outputs":[],"source":["class DQN(torch.nn.Module):\n","  def __init__(self,n_act):\n","    super(DQN,self).__init__()\n","    self.fc1 = torch.nn.Linear(256, 256)\n","    self.fc2 = torch.nn.Linear(256, n_act)\n","  def forward(self,x):\n","    x = x.view((-1,256))\n","    x = self.fc1(x)\n","    x = self.fc2(x)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"VWP0oC3fZ3gl"},"source":["# Initialize"]},{"cell_type":"markdown","metadata":{"id":"O-vfyF6iDtfP"},"source":["### load model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WS0qfHErbbMc"},"outputs":[],"source":["Load_File=0\n","Old_File=f\"DoubleDQN+VAE_model/Model-{Load_File}.pt\"\n","if Load_File>0:\n","  Log= np.load(f\"DoubleDQN+VAE_model/Log-{Load_File}.npy\", allow_pickle=True).item()\n","else:\n","  Log={\"TrainReward\":[],\"TestReward\":[],\"Loss\":[]}"]},{"cell_type":"markdown","metadata":{"id":"Q8Ae5G7sDtfU"},"source":["### env"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m9OEfP8WxULF"},"outputs":[],"source":["class ImageEnv(gym.Wrapper):\n","  def __init__(self,env,stack_frames=4,delay_op=50):\n","    super(ImageEnv, self).__init__(env)\n","    self.delay_op = delay_op\n","    self.stack_frames = stack_frames\n","  def reset(self):\n","    s, info = self.env.reset()\n","    for i in range(self.delay_op):\n","      s, r, terminated, truncated, info = self.env.step(0)\n","      s=torch.tensor((s[:84, 6:90]/255.0)-0.5).reshape((1,-1))\n","      with torch.no_grad():\n","        s, log_var = model.encoder(s.float())\n","      self.stacked_state = np.tile( s , (self.stack_frames,1) )  # [4, 84, 84]\n","    return self.stacked_state, info\n","\n","  def step(self, action):\n","    reward = 0\n","    for _ in range(self.stack_frames):\n","      s, r, terminated, truncated, info = self.env.step(action)\n","      if r==-100:terminated=True\n","      s=torch.tensor((s[:84, 6:90]/255.0)-0.5).reshape((1,-1))\n","      with torch.no_grad():\n","        s, log_var = model.encoder(s.float())\n","      reward += r\n","      if terminated or truncated or r<-80:break\n","      self.stacked_state = np.concatenate((self.stacked_state[1:], s), axis=0)\n","    return self.stacked_state, reward, terminated, truncated, info"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uhbUUe6j25S5","scrolled":true},"outputs":[],"source":["env=gym.make('CarRacing-v3',render_mode=\"rgb_array\",domain_randomize=False, continuous=False)\n","env = gym_wrap.GrayscaleObservation(env)\n","env = ImageEnv(env)"]},{"cell_type":"markdown","metadata":{"id":"T2ZraJED0kT-"},"source":["# 搭建智能體Agent的類別"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AhLrFKG5bExq"},"outputs":[],"source":["class DQNAgent():\n","  def __init__(self,gamma=0.9,eps_low=0.1,lr=0.00025):\n","    self.env = env\n","    self.n_act=self.env.action_space.n\n","    self.PredictDQN= DQN(self.n_act)\n","    self.TargetDQN= DQN(self.n_act)\n","    if Load_File>0:\n","      self.PredictDQN.load_state_dict(torch.load(Old_File))\n","      self.TargetDQN.load_state_dict(torch.load(Old_File))\n","    self.PredictDQN.to(device)\n","    self.TargetDQN.to(device)\n","    self.LossFun=torch.nn.SmoothL1Loss()\n","    self.optimizer=torch.optim.Adam(self.PredictDQN.parameters(),lr=lr)\n","    self.gamma=gamma\n","    self.eps_low=eps_low\n","    self.rb=ReplayBuffer(max_size=10000, num_steps=1)\n","  def PredictA(self,s):\n","    with torch.no_grad():\n","      s_tensor = torch.FloatTensor(s).to(device)\n","      q_values = self.PredictDQN(s_tensor)\n","      return torch.argmax(q_values).item()\n","  def SelectA(self,a):\n","    return self.env.action_space.sample() if np.random.random()<self.EPS else a\n","  def Train(self,N_EPISODES):\n","    for i in tqdm(range(Load_File,N_EPISODES)):\n","      self.EPS=max(1-(i*(1-self.eps_low)/(2*N_EPISODES/10)),self.eps_low)\n","      total_reward=0\n","      s,_=self.env.reset()\n","      while True:\n","        a=self.SelectA(self.PredictA(torch.tensor(s)))\n","        s_,r,done,stop,_=self.env.step(a)\n","        self.rb.append(s,a,r,s_,done)\n","        if self.rb.size > 200 and i%self.rb.num_steps==0:self.Learn()\n","        if i % 20==0:  self.TargetDQN.load_state_dict(self.PredictDQN.state_dict())\n","        s=s_\n","        total_reward+=r\n","        if done or stop:break\n","      print(f\"\\n{total_reward}\")\n","      Log[\"TrainReward\"].append(total_reward)\n","      if i % 10 == 9:\n","        test_reward=self.Test()\n","        print(f\"\\n訓練次數{i+1}，總回報{test_reward}\")\n","        Log[\"TestReward\"].append(test_reward)\n","        torch.save(self.PredictDQN.state_dict(), f\"DQN+VAE_model/Model-{i+1}.pt\")\n","        np.save(f\"DQN+VAE_model/Log-{i+1}.npy\", Log)\n","  def Learn(self):\n","    self.optimizer.zero_grad()\n","    batch_s, batch_a, batch_r, batch_s_, batch_done=self.rb.sample(32)\n","    predict_Q = (self.PredictDQN(batch_s.to(device))*F.one_hot(batch_a.long().to(device),self.n_act)).sum(1,keepdims=True)\n","    with torch.no_grad():\n","      target_Q = batch_r.to(device)+(1-batch_done.to(device))*self.gamma*self.TargetDQN(batch_s_.to(device)).max(1,keepdims=True)[0]\n","    loss = self.LossFun(predict_Q, target_Q)\n","    Log[\"Loss\"].append(float(loss))\n","    loss.backward()\n","    self.optimizer.step()\n","  def Test(self,VIDEO=False):\n","    total_reward=0\n","    video=[]\n","    s,_=self.env.reset()\n","    while True:\n","      video.append(self.env.render())\n","      a=self.PredictA(s)\n","      s,r,done,stop,_=self.env.step(a)\n","      total_reward+=r\n","      if done or stop:break\n","    if VIDEO:\n","      patch = plt.imshow(video[0]) #產生展示圖形物件\n","      plt.axis('off') #關閉坐標軸\n","      def animate(i): #設定更換影格的函數\n","        patch.set_data(video[i])\n","        #plt.gcf()=>建新繪圖區 animate=>更換影格函數 frames=>影格數 interval=>影隔間距(毫秒)\n","      anim = animation.FuncAnimation(plt.gcf(),animate,frames=len(video),interval=200)\n","      anim.save('Taxi.mp4') #儲存為mp4擋\n","    return total_reward\n","  def Record(self):\n","    total_reward=0\n","    s,_=self.env.reset()\n","    while True:\n","      image=self.env.render()\n","      plt.imshow(image)\n","      #plt.imsave(f\"/content/drive/MyDrive/recording/{str(int(time.time()))}.png\", image)\n","      a=self.PredictA(s)\n","      s,r,done,stop,_=self.env.step(a)\n","      print(r)\n","      total_reward+=r\n","      plt.pause(0.1)\n","      #清除目前的顯示\n","      display.clear_output(wait=True)\n","      if done or stop:break\n","    print(total_reward)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NyD5MRkycJKL","outputId":"ee92b979-75e6-45c6-ff7a-80fc11201f5b"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|                                       | 1/5000 [00:12<16:56:13, 12.20s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","-1.3789473684209566\n"]},{"name":"stderr","output_type":"stream","text":["  0%|                                       | 2/5000 [00:33<24:34:37, 17.70s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","-26.725748502994442\n"]},{"name":"stderr","output_type":"stream","text":["  0%|                                       | 3/5000 [00:53<25:55:41, 18.68s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","-43.52941176470624\n"]},{"name":"stderr","output_type":"stream","text":["  0%|                                       | 4/5000 [01:14<27:18:42, 19.68s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","-53.955223880597785\n"]},{"name":"stderr","output_type":"stream","text":["  0%|                                       | 5/5000 [01:27<23:43:48, 17.10s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","-23.626710097719805\n"]},{"name":"stderr","output_type":"stream","text":["  0%|                                       | 6/5000 [01:37<20:25:16, 14.72s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","-4.096369636963637\n"]}],"source":["Agent=DQNAgent(gamma=0.95,eps_low=0.05,lr=0.00025)\n","Agent.Train(N_EPISODES=5000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QJvLkbBOtFjm"},"outputs":[],"source":["Agent.Record()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZbbkagEFDtfa"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1Q3VyWGWMXTip1bFxHN9yF628x50YMb_S","timestamp":1737165535125},{"file_id":"1r5QT83LxUHE47Lex9v9P55s7eb_W0mHC","timestamp":1736245847989},{"file_id":"1O1KfjoTBUrBCnyn4oXtG4lcTEvRSZK7G","timestamp":1735479867704},{"file_id":"18yt9b6qYCT2PsLDYbl9fv6zRcSQvmi0n","timestamp":1709199071555},{"file_id":"1WRLanvHf4yYOnDBxmb0n1mbrLON0KMQU","timestamp":1708675711282},{"file_id":"13Cp-YFwmlHN3MbI7_xlKuLd_y_TaPV-0","timestamp":1702823835064},{"file_id":"1aMcCpvOHmXrOq1JcpI7evtg_4ZvR4qVH","timestamp":1702822403410},{"file_id":"1xHVDpXOYdYhmF3tU9vPo2TaMb81FA3Gl","timestamp":1702274368848},{"file_id":"1MKlvW9tFlfUpTKXu42vIdU66ffXCLYFx","timestamp":1701668882207},{"file_id":"1sbhFnBreRKtQfdR7Ta5P5ndy1xqZV7z3","timestamp":1699250308091},{"file_id":"1q95n7kJ49u2_x8SyBPyfHTB-_HfZ_wFt","timestamp":1693963108981},{"file_id":"1K98cGRSf_HKeLpHpuChr8vtaaMjPE-7x","timestamp":1693961359885},{"file_id":"1S2n19RA0RAkTfq_uA7vGSUBHDZMHTRAK","timestamp":1693878549390},{"file_id":"1DLZ6g1KLbo6VVZXw4zJ3xSxYO-U18ngr","timestamp":1693813383392},{"file_id":"1ipxvXg17g79lUSrBgMEivSDBot1LaN8H","timestamp":1693566531232},{"file_id":"1FfCLgXyAyL3yb2o92dcm3qv3uF_A22k5","timestamp":1693531204519}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
