{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27786,"status":"ok","timestamp":1737337048389,"user":{"displayName":"吳苡柔","userId":"11552279734881594425"},"user_tz":-480},"id":"ndeBahc3sCpH","outputId":"20e5901c-7553-4f0c-9b3e-a04e596e84be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"6xpMm1O7X7rh"},"source":["# 安裝gymnassium套件"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65539,"status":"ok","timestamp":1737337113921,"user":{"displayName":"吳苡柔","userId":"11552279734881594425"},"user_tz":-480},"id":"ovWDVDItX-w9","outputId":"f6223cbf-6c74-49ef-d270-884428e5a65e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gymnasium\n","  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.12.2)\n","Collecting farama-notifications>=0.0.1 (from gymnasium)\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n","Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Installing collected packages: farama-notifications, gymnasium\n","Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0\n","Collecting swig\n","  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n","Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: swig\n","Successfully installed swig-4.3.0\n","Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.11/dist-packages (1.0.0)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (1.26.4)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (3.1.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.12.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (0.0.4)\n","Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n","  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (2.6.1)\n","Requirement already satisfied: swig==4.* in /usr/local/lib/python3.11/dist-packages (from gymnasium[box2d]) (4.3.0)\n","Building wheels for collected packages: box2d-py\n","  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp311-cp311-linux_x86_64.whl size=2379446 sha256=b00074655f7a8ffdb08aa510e954ad440052917b5577a81b77fc617657f03ee2\n","  Stored in directory: /root/.cache/pip/wheels/ab/f1/0c/d56f4a2bdd12bae0a0693ec33f2f0daadb5eb9753c78fa5308\n","Successfully built box2d-py\n","Installing collected packages: box2d-py\n","Successfully installed box2d-py-2.3.5\n"]}],"source":["!pip install gymnasium\n","!pip install swig\n","!pip install gymnasium[box2d]"]},{"cell_type":"markdown","metadata":{"id":"amCJWZusYFA7"},"source":["# import 必要套件"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4DQXqSMYKJF"},"outputs":[],"source":["import random\n","import time,math\n","import numpy as np\n","import gymnasium as gym\n","import gymnasium.wrappers as gym_wrap\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation #輸出動畫影片\n","import matplotlib.font_manager as plt_font\n","twfont1=plt_font.FontProperties(fname=\"/content/drive/MyDrive/解密AI黑盒子分享/字型/kaiu.ttf\")\n","from IPython import display\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Rp64v20dxLw"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import collections\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5XsxGnHkQ6i"},"outputs":[],"source":["class ImageEnv(gym.Wrapper):\n","  def __init__(self,env,stack_frames=4,delay_op=50):\n","    super(ImageEnv, self).__init__(env)\n","    self.delay_op = delay_op\n","    self.stack_frames = stack_frames\n","  def reset(self):\n","    s, info = self.env.reset()\n","    for i in range(self.delay_op):\n","      s, r, terminated, truncated, info = self.env.step(0)\n","      s=s[:84, 6:90]/255.0\n","      self.stacked_state = np.tile( s , (self.stack_frames,1,1) )  # [4, 84, 84]\n","    return self.stacked_state, info\n","\n","  def step(self, action):\n","    reward = 0\n","    for _ in range(self.stack_frames):\n","      s, r, terminated, truncated, info = self.env.step(action)\n","      if r==-100:terminated=True\n","      s=s[:84, 6:90]/255.0\n","      reward += r\n","      if terminated or truncated:break\n","      self.stacked_state = np.concatenate((self.stacked_state[1:], s[np.newaxis]), axis=0)\n","    return self.stacked_state, reward, terminated, truncated, info"]},{"cell_type":"markdown","metadata":{"id":"Av7Taco9YPQQ"},"source":["# 建立Replay Buffer類別"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysgw8Va1I3TF"},"outputs":[],"source":["class ReplayBuffer:\n","  def __init__(self,max_size=int(1e5), num_steps=1):\n","    self.s = np.zeros((max_size,4,84,84), dtype=np.float32)\n","    self.a = np.zeros((max_size,), dtype=np.int64)\n","    self.r = np.zeros((max_size, 1), dtype=np.float32)\n","    self.s_ = np.zeros((max_size,4,84,84), dtype=np.float32)\n","    self.done = np.zeros((max_size, 1), dtype=np.float32)\n","    self.ptr = 0\n","    self.size = 0\n","    self.max_size = max_size\n","    self.num_steps = num_steps\n","\n","  def append(self,s,a,r,s_,done):\n","    self.s[self.ptr] = s\n","    self.a[self.ptr] = a\n","    self.r[self.ptr] = r\n","    self.s_[self.ptr] = s_\n","    self.done[self.ptr] = done\n","    self.ptr = (self.ptr + 1) % self.max_size\n","    self.size = min(self.size+1,self.max_size)\n","  def sample(self, batch_size):\n","    ind = np.random.randint(0, self.size, batch_size)\n","    return torch.FloatTensor(self.s[ind]),torch.LongTensor(self.a[ind]),torch.FloatTensor(self.r[ind]),torch.FloatTensor(self.s_[ind]),torch.FloatTensor(self.done[ind])"]},{"cell_type":"markdown","metadata":{"id":"VySf61of0cRe"},"source":["# 搭建DQN神經網路的類別"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"045GAtxseMMq"},"outputs":[],"source":["class DQN(torch.nn.Module):\n","  def __init__(self,n_act):\n","    super(DQN,self).__init__()\n","    self.conv1 = torch.nn.Conv2d(4, 16, kernel_size=8, stride=4)  #[N,4,84,84]->[N,16,20,20]\n","    self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=4, stride=2)  #[N,16,20,20]->[N,32,9,9]\n","    self.fc1 = torch.nn.Linear(32 * 9 * 9, 256)\n","    self.fc2 = torch.nn.Linear(256, n_act)\n","  def forward(self,x):\n","    x = F.relu(self.conv1(x))\n","    x = F.relu(self.conv2(x))\n","    x = x.view((-1, 32 * 9 * 9))\n","    x = self.fc1(x)\n","    x = self.fc2(x)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"VWP0oC3fZ3gl"},"source":["# 設定是否載入模型參數，舊參數檔路徑，新參數檔路徑"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WS0qfHErbbMc"},"outputs":[],"source":["Load_File=300\n","folder=\"/content/drive/MyDrive/強化學習期末專題(小組)/DoubleDQN/model/\"\n","Old_File=folder+f\"model_DoubleDQN-{Load_File}.pt\"\n","if Load_File>0:\n","  Log= np.load(folder+f\"Log_DoubleDQN-{Load_File}.npy\", allow_pickle=True).item()\n","else:\n","  Log={\"TrainReward\":[],\"TestReward\":[],\"Loss\":[]} # 確認模型如何變好"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eNoo_tRKkYmX"},"outputs":[],"source":["env=gym.make('CarRacing-v3',render_mode=\"rgb_array\",domain_randomize=False, continuous=False)\n","env = gym_wrap.GrayscaleObservation(env)\n","env = ImageEnv(env)"]},{"cell_type":"markdown","metadata":{"id":"T2ZraJED0kT-"},"source":["# 搭建智能體Agent的類別"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXp7ACduVYK3"},"outputs":[],"source":["class DQNAgent():\n","  def __init__(self,gamma=0.9,eps_low=0.1,lr=0.001):\n","    self.env=env\n","    self.n_act=self.env.action_space.n\n","    self.PredictDQN= DQN(self.n_act)\n","    self.TargetDQN= DQN(self.n_act)\n","    if Load_File>0:\n","      self.PredictDQN.load_state_dict(torch.load(Old_File))\n","      self.TargetDQN.load_state_dict(torch.load(Old_File))\n","    self.PredictDQN.to(device)\n","    self.TargetDQN.to(device)\n","    self.LossFun=torch.nn.SmoothL1Loss()\n","    self.optimizer=torch.optim.Adam(self.PredictDQN.parameters(),lr=lr)\n","    self.gamma=gamma\n","    self.eps_low=eps_low\n","    self.rb=ReplayBuffer(max_size=2000, num_steps=4)\n","  def PredictA(self,s):\n","    with torch.no_grad():\n","      return torch.argmax(self.PredictDQN(torch.FloatTensor(s).to(device))).item()\n","  def SelectA(self,a):\n","    return self.env.action_space.sample() if np.random.random()<self.EPS else a\n","  def Train(self,N_EPISODES):\n","    for i in tqdm(range(Load_File,N_EPISODES)):\n","      self.EPS=self.eps_low+(1-self.eps_low)*math.exp(-i*5/(N_EPISODES))\n","      total_reward=0\n","      s,_=self.env.reset()\n","      while True:\n","        a=self.SelectA(self.PredictA(s))\n","        s_,r,done,stop,_=self.env.step(a)\n","        self.rb.append(s,a,r,s_,done)\n","        if self.rb.size > 200 and i%self.rb.num_steps==0: self.Learn()\n","        if i % 20==0:  self.TargetDQN.load_state_dict(self.PredictDQN.state_dict())\n","        s=s_\n","        total_reward+=r\n","        if done or stop:break\n","      Log[\"TrainReward\"].append(total_reward)\n","      if i % 100 == 99:\n","        test_reward=self.Test()\n","        print(f\"\\n訓練次數{i+1}，總回報{test_reward}\")\n","        Log[\"TestReward\"].append(test_reward)\n","        torch.save(self.PredictDQN.state_dict(), f\"{folder}/model_DoubleDQN-{i+Load_File+1}.pt\")\n","        np.save(f\"{folder}/Log_DoubleDQN-{i+Load_File+1}.npy\", Log)\n","  def Learn(self):\n","    self.optimizer.zero_grad()\n","    batch_s,batch_a,batch_r,batch_s_,batch_done=self.rb.sample(32)\n","    predict_Q=(self.PredictDQN(batch_s.to(device))*F.one_hot(batch_a.long().to(device),self.n_act)).sum(1,keepdims=True)\n","    with torch.no_grad():\n","      next_act=self.PredictDQN(batch_s_.to(device)).argmax(1,keepdims=True)\n","      target_Q_values=self.TargetDQN(batch_s_.to(device)).gather(1,next_act)\n","      target_Q=batch_r.to(device)+(1-batch_done.to(device))*self.gamma*target_Q_values\n","    loss=self.LossFun(predict_Q,target_Q)\n","    Log[\"Loss\"].append(float(loss))\n","    loss.backward()\n","    self.optimizer.step()\n","  def Test(self,VIDEO=False):\n","    total_reward=0\n","    video=[]\n","    s,_=self.env.reset()\n","    while True:\n","      video.append(self.env.render())\n","      a=self.PredictA(s)\n","      s,r,done,stop,_=self.env.step(a)\n","      total_reward+=r\n","      if done or stop:break\n","    if VIDEO:\n","      patch = plt.imshow(video[0]) #產生展示圖形物件\n","      plt.axis('off') #關閉坐標軸\n","      def animate(i): #設定更換影格的函數\n","        patch.set_data(video[i])\n","        #plt.gcf()=>建新繪圖區 animate=>更換影格函數 frames=>影格數 interval=>影隔間距(毫秒)\n","      anim = animation.FuncAnimation(plt.gcf(),animate,frames=len(video),interval=200)\n","      anim.save('Car_racing.mp4') #儲存為mp4擋\n","    return total_reward"]},{"cell_type":"markdown","metadata":{"id":"_8-ZPWXRxiKU"},"source":["# 實體化智能體Agent，開始訓練智能體"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"bc6MLVFkxsWM","outputId":"52df9cf0-e683-4e04-c53e-5122eb3286ce"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-10-57f58d70467a>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.PredictDQN.load_state_dict(torch.load(Old_File))\n","<ipython-input-10-57f58d70467a>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  self.TargetDQN.load_state_dict(torch.load(Old_File))\n","  1%|          | 100/15700 [18:12<60:59:30, 14.08s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","訓練次數400，總回報-94.99999999999898\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 127/15700 [22:59<45:44:45, 10.58s/it]"]}],"source":["Agent=DQNAgent(gamma=0.95,eps_low=0.05,lr=0.00025)\n","Agent.Train(N_EPISODES=16000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AMPBV-8acxMc"},"outputs":[],"source":["plt.figure(figsize=(8,5)) #設定繪圖區大小\n","#繪圖區的標題，設定用中文字體twfont1，字體大小15\n","plt.title(\"TestReward vs episodes\",fontsize=15)\n","#設定橫軸和縱軸的標題\n","plt.xlabel(\"TestReward\",fontsize=15)\n","plt.ylabel(\"episodes(x100)\",fontsize=15)\n","plt.plot(Log[\"TestReward\"],\"b-\",label=\"Reward\")\n","plt.legend()"]},{"cell_type":"markdown","metadata":{"id":"KhUoD5fMXx4h"},"source":["## 測試智能體平均表現\n"]},{"cell_type":"markdown","metadata":{"id":"wccNLwiUxvxm"},"source":["## 生成智能體Agent測試影片"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gN5mLIF_Pchh"},"outputs":[],"source":["Agent.Test(VIDEO=True)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1W8crYz7wPs5qJmbBerc_UTnAGiD12vkM","timestamp":1736145339896},{"file_id":"18K6erew48qzfnLLyATscRGFXYSwrYZSM","timestamp":1736145310733},{"file_id":"15SoGR67AUNtj4Y16bqzGVTlmByHYvV6h","timestamp":1736144366828},{"file_id":"1OstwfDaZFcNIx0iVMTSp95CDqN243icl","timestamp":1735536460263},{"file_id":"1WRLanvHf4yYOnDBxmb0n1mbrLON0KMQU","timestamp":1708675711282},{"file_id":"13Cp-YFwmlHN3MbI7_xlKuLd_y_TaPV-0","timestamp":1702823835064},{"file_id":"1aMcCpvOHmXrOq1JcpI7evtg_4ZvR4qVH","timestamp":1702822403410},{"file_id":"1xHVDpXOYdYhmF3tU9vPo2TaMb81FA3Gl","timestamp":1702274368848},{"file_id":"1MKlvW9tFlfUpTKXu42vIdU66ffXCLYFx","timestamp":1701668882207},{"file_id":"1sbhFnBreRKtQfdR7Ta5P5ndy1xqZV7z3","timestamp":1699250308091},{"file_id":"1q95n7kJ49u2_x8SyBPyfHTB-_HfZ_wFt","timestamp":1693963108981},{"file_id":"1K98cGRSf_HKeLpHpuChr8vtaaMjPE-7x","timestamp":1693961359885},{"file_id":"1S2n19RA0RAkTfq_uA7vGSUBHDZMHTRAK","timestamp":1693878549390},{"file_id":"1DLZ6g1KLbo6VVZXw4zJ3xSxYO-U18ngr","timestamp":1693813383392},{"file_id":"1ipxvXg17g79lUSrBgMEivSDBot1LaN8H","timestamp":1693566531232},{"file_id":"1FfCLgXyAyL3yb2o92dcm3qv3uF_A22k5","timestamp":1693531204519}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}